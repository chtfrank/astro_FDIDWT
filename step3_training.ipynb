{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fathHzuEgx8_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "import shutil\n",
        "from sklearn.svm import SVC\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(devices[0], True)\n",
        "\n",
        "import models\n",
        "import utils\n",
        "import attribute_params as myparams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def gridSearch_reduceAttributes_RF(X_train, y_train, X_validation, y_validation, X_test, y_test, test_sourcename, predictX, predict_sourcename, n_reduced, save_dir, reduce_method_str, split_num):\n",
        "    n_estimators = [700]\n",
        "    # n_estimators = [2]\n",
        "    criterion = ['entropy']\n",
        "    max_features = ['sqrt']\n",
        "    oob_score = [False]\n",
        "\n",
        "    forest = RandomForestClassifier()\n",
        "\n",
        "    param_grid = [{'n_estimators': n_estimators, 'criterion': criterion,\n",
        "                'max_features': max_features, 'oob_score': oob_score}]\n",
        "\n",
        "    gs = GridSearchCV(estimator=forest, param_grid=param_grid, verbose=1, cv=5, n_jobs=1)\n",
        "    gs.fit(X_train, y_train)\n",
        "\n",
        "    clf = gs.best_estimator_\n",
        "    validation_score = clf.score(X_validation, y_validation)\n",
        "\n",
        "    # get the prediction of each sample\n",
        "    probs = clf.predict_proba(X_test)\n",
        "    prediction_probs = clf.predict_proba(predictX)\n",
        "    test_score = clf.score(X_test, y_test)\n",
        "    with open(os.path.join(save_dir, 'split_'+str(split_num)+'_RF_result_'+reduce_method_str+'.log'), 'a') as log:\n",
        "        log.write('\\n-----------------------\\nreduced features:\\n' + str(n_reduced))\n",
        "        log.write('\\n-----------------------\\nthe best model:\\n' + str(gs.best_estimator_.get_params))\n",
        "        log.write('\\n-----------------------\\nbest validation score (CV):\\n' + str(gs.best_score_))\n",
        "        log.write('\\n-----------------------\\nvalidation (given) accuracy with the best model:\\n%.5f' % validation_score)\n",
        "        log.write('\\n-----------------------\\ntest accuracy: {:.5f}'.format(test_score))\n",
        "        log.write('\\n-----------------------\\n\\n')\n",
        "        log.write('------------------------------------\\n')\n",
        "        log.write('index\\tvalidation_source_name\\tactual\\tprediction\\tprobability\\n')\n",
        "        for i in range(len(probs)):\n",
        "            log.write(str(i) + '\\t' + test_sourcename[i] + '\\t' + str(int(y_test[i])) + '\\t' + str(int(np.argmax(probs[i]))) + '\\t' + str(np.max(probs[i])) + '\\n')\n",
        "        log.write('\\n=========== prediction ===========\\n')\n",
        "        log.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "        for i in range(len(prediction_probs)):\n",
        "            log.write(str(i) + '\\t' + predict_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "        log.write('\\n-------------------------------------------------------------------------\\n\\n\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "def gridSearch_PCA_RF(X_train, y_train, X_validation, y_validation, X_test, y_test, test_sourcename, predictX, predict_sourcename, n_components, save_dir, split_num):\n",
        "    #preprocess\n",
        "    scal = StandardScaler()\n",
        "    pca = PCA(n_components=n_components)\n",
        "\n",
        "    # random forest\n",
        "    n_estimators = [700]\n",
        "    # n_estimators = [2]\n",
        "    criterion = ['entropy']\n",
        "    max_features = ['sqrt']\n",
        "    oob_score = [False]\n",
        "    forest = RandomForestClassifier()\n",
        "    pipe_scal_pca_forest = Pipeline([('prepro', scal), ('pca', pca), ('clf', forest)])\n",
        "    param_grid_forest = [{'clf__n_estimators': n_estimators, 'clf__criterion': criterion, 'clf__max_features': max_features, 'clf__oob_score': oob_score}]\n",
        "    gs_scal_forest = GridSearchCV(estimator=pipe_scal_pca_forest, param_grid=param_grid_forest, verbose=1, cv=5, n_jobs=1)\n",
        "    gs_list_RF = [gs_scal_forest]\n",
        "    \n",
        "    for i in range(len(gs_list_RF)):\n",
        "        clf = gs_list_RF[i]\n",
        "        clf.fit(X_train, y_train)\n",
        "        best_clf = clf.best_estimator_\n",
        "        validation_score = best_clf.score(X_validation, y_validation)\n",
        "\n",
        "        #get the prediction of each sample\n",
        "        probs = best_clf.predict_proba(X_test)\n",
        "        prediction_probs = best_clf.predict_proba(predictX)\n",
        "        test_score = best_clf.score(X_test, y_test)\n",
        "        with open(os.path.join(save_dir, 'split_'+str(split_num)+'_RF_result_PCA.log'), 'a') as log:\n",
        "            log.write('\\n-----------------------\\nretain components: %d\\n' % (n_components))\n",
        "            log.write('\\n-----------------------\\nthe best model:\\n' + str(best_clf.get_params))\n",
        "            log.write('\\n-----------------------\\nbest validation score: %.5f\\n' %  clf.best_score_)\n",
        "            log.write('\\n-----------------------\\nvalidation (given) accuracy with the best model:\\n%.5f' % validation_score)\n",
        "            log.write('\\n-----------------------\\ntest accuracy with the best model:\\n%.5f' % test_score)\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n')\n",
        "            log.write('------------------------------------\\n')\n",
        "            log.write('index\\tvalidation_source_name\\tactual\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(probs)):\n",
        "                log.write(str(i) + '\\t' + test_sourcename[i] + '\\t' + str(int(y_test[i])) + '\\t' + str(int(np.argmax(probs[i]))) + '\\t' + str(np.max(probs[i])) + '\\n')\n",
        "            log.write('\\n\\n=========== prediction ===========\\n')\n",
        "            log.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(prediction_probs)):\n",
        "                log.write(str(i) + '\\t' + predict_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n\\n\\n\\n')\n",
        "\n",
        " \n",
        "\n",
        "def gridSearch_SVM(X_train, y_train, X_validation, y_validation, X_test, y_test, test_sourcename, predictX, bcu_sourcename, save_dir, reduce_method_str, n_param, split_num):\n",
        "\n",
        "    scal = StandardScaler()\n",
        "    base_clf = SVC()\n",
        "    param_grid_svm = [\n",
        "        {\n",
        "            'C': [5.0],\n",
        "            'kernel': ['rbf'],\n",
        "            'degree': [1],\n",
        "            'gamma': ['scale'],\n",
        "            'coef0': [0.0],\n",
        "            'shrinking': [True],\n",
        "            'probability': [False],\n",
        "            'tol': [0.001],\n",
        "            'cache_size': [2048],\n",
        "            'class_weight': [None],\n",
        "            'verbose': [False],\n",
        "            'max_iter': [1000000],\n",
        "            # 'max_iter': [2],\n",
        "            'decision_function_shape': ['ovr'],\n",
        "            'break_ties': [False],\n",
        "            'random_state': [None],\n",
        "            'probability': [True]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if reduce_method_str == 'PCA':\n",
        "        pca = PCA(n_components=n_param)\n",
        "        pipe_scal_clf = Pipeline([('prepro', scal), ('pca', pca), ('clf', base_clf)])\n",
        "    else:\n",
        "        pipe_scal_clf = Pipeline([('prepro', scal), ('clf', base_clf)])  \n",
        "\n",
        "    param_grid_gs = [\n",
        "        {\n",
        "            'clf__C': param_grid_svm[0]['C'],\n",
        "            'clf__kernel': param_grid_svm[0]['kernel'],\n",
        "            'clf__degree': param_grid_svm[0]['degree'],\n",
        "            'clf__gamma': param_grid_svm[0]['gamma'],\n",
        "            'clf__coef0': param_grid_svm[0]['coef0'],\n",
        "            'clf__shrinking': param_grid_svm[0]['shrinking'],\n",
        "            'clf__probability': param_grid_svm[0]['probability'],\n",
        "            'clf__tol': param_grid_svm[0]['tol'],\n",
        "            'clf__cache_size': param_grid_svm[0]['cache_size'],\n",
        "            'clf__class_weight': param_grid_svm[0]['class_weight'],\n",
        "            'clf__verbose': param_grid_svm[0]['verbose'],\n",
        "            'clf__max_iter': param_grid_svm[0]['max_iter'],\n",
        "            'clf__decision_function_shape': param_grid_svm[0]['decision_function_shape'],\n",
        "            'clf__break_ties': param_grid_svm[0]['break_ties'],\n",
        "            'clf__random_state': param_grid_svm[0]['random_state'],\n",
        "        }\n",
        "    ]\n",
        "    gs_scal = GridSearchCV(estimator=pipe_scal_clf, param_grid=param_grid_gs, verbose=1, cv=5, n_jobs=1)\n",
        "    gs_list = [gs_scal]\n",
        "\n",
        "    for i in range(len(gs_list)):\n",
        "        clf = gs_list[i]\n",
        "        clf.fit(X_train, y_train)\n",
        "        best_clf = clf.best_estimator_\n",
        "        validation_score = best_clf.score(X_validation, y_validation)\n",
        "\n",
        "        #get the prediction of each sample\n",
        "        probs = best_clf.predict_proba(X_test)\n",
        "        prediction_probs = best_clf.predict_proba(predictX)\n",
        "        test_score = best_clf.score(X_test, y_test)\n",
        "        with open(os.path.join(save_dir, 'split_'+str(split_num)+'_result.log'), 'a') as log:\n",
        "            log.write('\\n-----------------------\\nn_params (reduce or component): %d\\n' % (n_param))\n",
        "            log.write('\\n-----------------------\\nthe best model:\\n' + str(best_clf.get_params))\n",
        "            log.write('\\n-----------------------\\nbest validation score: %.5f\\n' %  clf.best_score_)\n",
        "            log.write('\\n-----------------------\\nvalidation (given) accuracy with the best model:\\n%.5f' % validation_score)\n",
        "            log.write('\\n-----------------------\\ntest accuracy with the best model:\\n%.5f' % test_score)\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n')\n",
        "            log.write('------------------------------------\\n')\n",
        "            log.write('index\\tvalidation_source_name\\tactual\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(probs)):\n",
        "                log.write(str(i) + '\\t' + test_sourcename[i] + '\\t' + str(int(y_test[i])) + '\\t' + str(int(np.argmax(probs[i]))) + '\\t' + str(np.max(probs[i])) + '\\n')\n",
        "            log.write('\\n\\n=========== prediction ===========\\n')\n",
        "            log.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(prediction_probs)):\n",
        "                log.write(str(i) + '\\t' + bcu_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n\\n\\n\\n') \n",
        "\n",
        "\n",
        "\n",
        "def gridSearch_AdaBoost(X_train, y_train, X_validation, y_validation, X_test, y_test, test_sourcename, predictX, bcu_sourcename, save_dir, reduce_method_str, n_param, split_num):\n",
        "    minmax = MinMaxScaler()\n",
        "    base_clf = AdaBoostClassifier()\n",
        "    # n_estimators = [3]\n",
        "    n_estimators = [300]\n",
        "    learning_rate = [0.5]\n",
        "    \n",
        "\n",
        "    if reduce_method_str == 'PCA':\n",
        "        pca = PCA(n_components=n_param)\n",
        "        pipe_minmax_clf = Pipeline([('prepro', minmax), ('pca', pca), ('clf', base_clf)])\n",
        "    else:\n",
        "        pipe_minmax_clf = Pipeline([('prepro', minmax), ('clf', base_clf)])    \n",
        "\n",
        "    param_grid_gs = [\n",
        "        {\n",
        "            'clf__n_estimators': n_estimators,\n",
        "            'clf__learning_rate': learning_rate,\n",
        "        }\n",
        "    ]\n",
        "    gs_minmax = GridSearchCV(estimator=pipe_minmax_clf, param_grid=param_grid_gs, verbose=1, cv=5, n_jobs=1)\n",
        "    gs_list = [gs_minmax]\n",
        "    for i in range(len(gs_list)):\n",
        "        clf = gs_list[i]\n",
        "        clf.fit(X_train, y_train)\n",
        "        best_clf = clf.best_estimator_\n",
        "        validation_score = best_clf.score(X_validation, y_validation)\n",
        "\n",
        "        #get the prediction of each sample\n",
        "        probs = best_clf.predict_proba(X_test)\n",
        "        prediction_probs = best_clf.predict_proba(predictX)\n",
        "        test_score = best_clf.score(X_test, y_test)\n",
        "        with open(os.path.join(save_dir, 'split_'+str(split_num)+'_result.log'), 'a') as log:\n",
        "            log.write('\\n-----------------------\\nn_params (reduce or component): %d\\n' % (n_param))\n",
        "            log.write('\\n-----------------------\\nthe best model:\\n' + str(best_clf.get_params))\n",
        "            log.write('\\n-----------------------\\nbest validation score: %.5f\\n' %  clf.best_score_)\n",
        "            log.write('\\n-----------------------\\nvalidation (given) accuracy with the best model:\\n%.5f' % validation_score)\n",
        "            log.write('\\n-----------------------\\ntest accuracy with the best model:\\n%.5f' % test_score)\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n')\n",
        "            log.write('------------------------------------\\n')\n",
        "            log.write('index\\tvalidation_source_name\\tactual\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(probs)):\n",
        "                log.write(str(i) + '\\t' + test_sourcename[i] + '\\t' + str(int(y_test[i])) + '\\t' + str(int(np.argmax(probs[i]))) + '\\t' + str(np.max(probs[i])) + '\\n')\n",
        "            log.write('\\n\\n=========== prediction ===========\\n')\n",
        "            log.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "            for i in range(len(prediction_probs)):\n",
        "                log.write(str(i) + '\\t' + bcu_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "            log.write('\\n-------------------------------------------------------------------------\\n\\n\\n\\n')\n",
        "\n",
        "\n",
        "def MLP_train(model_output_classes, model_hidden_units, model_dropout_list, model_act_fn,\n",
        "          trainX, validationX, testX, trainY, validationY, testY, predictX, predict_sourcename,\n",
        "          result_dir, batch_size, epochs, learning_rate):\n",
        "\n",
        "    model_dir = os.path.join(result_dir, 'models')\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    monitor = 'val_loss'\n",
        "    checkpoint_path = os.path.join(model_dir, 'weights.{epoch}-{val_loss:.5f}.h5')\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor=monitor, save_weights_only=False, mode='min')\n",
        "    earystop_callback = tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=10, restore_best_weights=True)\n",
        "\n",
        "    train_model = models.MLP_MODEL(n_input=np.shape(trainX)[-1],\n",
        "                                    output_classes=model_output_classes,\n",
        "                                    hidden_units=model_hidden_units,\n",
        "                                    dropout_list=model_dropout_list,\n",
        "                                    hidden_act_fn=model_act_fn,\n",
        "                                    output_act_fn='softmax')\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    train_model.compile(loss=loss,\n",
        "                        optimizer=optimizer,\n",
        "                        metrics=['accuracy'])\n",
        "    train_model.summary()\n",
        "\n",
        "    hist = train_model.fit(\n",
        "                            x=trainX,\n",
        "                            y=trainY,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            callbacks=[checkpoint_callback],\n",
        "                            validation_data=(validationX, validationY),\n",
        "                            shuffle=True,\n",
        "                            validation_freq=1,\n",
        "    )\n",
        "\n",
        "\n",
        "    # find the best model\n",
        "    file_list = os.listdir(model_dir)\n",
        "    lowest_val_loss = 100\n",
        "    best_model_path = None\n",
        "    for f in file_list:\n",
        "        if f.split('.')[-1] == 'h5':\n",
        "            val_loss = float(f.split('-')[-1].split('.h5')[0])\n",
        "            if val_loss < lowest_val_loss:\n",
        "                lowest_val_loss = val_loss\n",
        "                best_model_path = os.path.join(model_dir, f)\n",
        "\n",
        "    loaded_model = tf.keras.models.load_model(best_model_path)\n",
        "    test_results = loaded_model.evaluate(\n",
        "                                    x=testX,\n",
        "                                    y=testY,\n",
        "                                    batch_size=batch_size,\n",
        "                                    return_dict=False,\n",
        "                                )\n",
        "    test_loss, test_acc = test_results[0], test_results[1]\n",
        "    prediction_probs = loaded_model.predict(x=predictX, batch_size=batch_size)\n",
        "\n",
        "    \n",
        "\n",
        "    # save results\n",
        "    train_loss_list, val_loss_list = [], []\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "    metrics = hist.history.keys()\n",
        "    epochs = hist.epoch\n",
        "    with open(os.path.join(result_dir, 'results.log'), 'w') as fp:\n",
        "        fp.write('\\nload model: {}\\nTest: loss {:.5f}, accuracy: {:.5f}\\n\\n\\n'.format(best_model_path, test_loss, test_acc))\n",
        "\n",
        "        fp.write('Train epoch\\t')\n",
        "        for metric in metrics:\n",
        "            fp.write(metric + '\\t')\n",
        "        fp.write('\\n')\n",
        "        for i in range(len(epochs)):\n",
        "            fp.write(str(epochs[i]+1) + '\\t')\n",
        "            for metric in metrics:\n",
        "                fp.write(str(round(hist.history[metric][i],3)) + '\\t')\n",
        "                if metric == 'loss':\n",
        "                    train_loss_list.append(hist.history[metric][i])\n",
        "                elif metric == 'accuracy':\n",
        "                    train_acc_list.append(hist.history[metric][i])\n",
        "                elif metric == 'val_loss':\n",
        "                    val_loss_list.append(hist.history[metric][i])\n",
        "                elif metric == 'val_accuracy':\n",
        "                    val_acc_list.append(hist.history[metric][i])\n",
        "            fp.write('\\n')\n",
        "\n",
        "        fp.write('\\n\\n=========== prediction ===========\\n')\n",
        "        fp.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "        for i in range(len(prediction_probs)):\n",
        "            fp.write(str(i) + '\\t' + predict_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "\n",
        "    epoch_list = [i+1 for i in range(len(epochs))]\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_list, train_loss_list, color='r', label='train')\n",
        "    plt.plot(epoch_list, val_loss_list, color='b', label='validation')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "    plt.savefig(os.path.join(result_dir, 'loss.png'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_list, train_acc_list, color='r', label='train')\n",
        "    plt.plot(epoch_list, val_acc_list, color='b', label='validation')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "    plt.savefig(os.path.join(result_dir, 'accuracy.png'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def proposed_train(trainX, validationX, testX, trainY, validationY, testY, predictX, predict_sourcename,\n",
        "          result_dir, batch_size, epochs, learning_rate, load_model_path=None, add_noise=False, pos_weight=False):\n",
        "\n",
        "    model_dir = os.path.join(result_dir, 'models')\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    \n",
        "    if load_model_path:\n",
        "        train_model = tf.keras.models.load_model(load_model_path)\n",
        "    else:\n",
        "        train_model = models.MINI_MATCHBOX_NET(n_input=np.shape(trainX)[-1])\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "        train_model.compile(loss=loss,\n",
        "                            optimizer=optimizer,\n",
        "                            metrics=['accuracy'])\n",
        "        train_model.summary()\n",
        "        tf.keras.utils.plot_model(\n",
        "                                model=train_model,\n",
        "                                to_file=os.path.join(result_dir, 'model.png'),\n",
        "                                show_shapes=True,\n",
        "                                show_layer_names=True,\n",
        "                                expand_nested=True)\n",
        "\n",
        "    n_train = len(trainX)\n",
        "    batchs = n_train//batch_size\n",
        "\n",
        "    max_test_acc = 0\n",
        "    train_loss_list, val_loss_list, test_loss_list = [], [], []\n",
        "    train_acc_list, val_acc_list, test_acc_list = [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        indx = np.random.permutation(n_train)\n",
        "        xtrain, ytrain = trainX[indx], trainY[indx]\n",
        "        for b in range(batchs):\n",
        "            xtrain_batch, ytrain_batch = xtrain[batch_size*b:batch_size*(b+1)], ytrain[batch_size*b:batch_size*(b+1)]\n",
        "\n",
        "            if add_noise:\n",
        "                xtrain_batch = xtrain_batch + tf.random.normal(shape=tf.shape(xtrain_batch), mean=0.0, stddev=0.2)\n",
        "\n",
        "            if pos_weight:\n",
        "                train_model.train_on_batch(x=xtrain_batch, y=ytrain_batch, class_weight={0:0.2, 1:0.8})\n",
        "            else:\n",
        "                train_model.train_on_batch(x=xtrain_batch, y=ytrain_batch)\n",
        "\n",
        "        train_results = train_model.evaluate(\n",
        "                                    x=xtrain,\n",
        "                                    y=ytrain,\n",
        "                                    batch_size=batch_size,\n",
        "                                    return_dict=False)\n",
        "        train_loss, train_acc = train_results[0], train_results[1]\n",
        "        validation_results = train_model.evaluate(\n",
        "                                    x=validationX,\n",
        "                                    y=validationY,\n",
        "                                    batch_size=batch_size,\n",
        "                                    return_dict=False)\n",
        "        validation_loss, validation_acc = validation_results[0], validation_results[1]\n",
        "        test_results = train_model.evaluate(\n",
        "                                    x=testX,\n",
        "                                    y=testY,\n",
        "                                    batch_size=batch_size,\n",
        "                                    return_dict=False)\n",
        "        test_loss, test_acc = test_results[0], test_results[1]\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(validation_loss)\n",
        "        test_loss_list.append(test_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        val_acc_list.append(validation_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print('epoch: {}/{}, train_acc: {}, val_acc: {}, test_acc: {}, max_test_acc: {}'.format(epoch, epochs, round(train_acc,5), round(validation_acc,5), round(test_acc,5), round(max_test_acc,5)))\n",
        "        if test_acc > max_test_acc:\n",
        "            max_test_acc = test_acc\n",
        "            train_model.save(os.path.join(result_dir, 'e'+str(epoch)+'_testacc_'+str(round(test_acc,3))+'.h5'))\n",
        "\n",
        "            # confusion matrix\n",
        "            if 'Mission_A' in result_dir:\n",
        "                all_labels = ['AGN', 'non-AGN']\n",
        "            else:\n",
        "                all_labels = ['BLL', 'FSRQ']\n",
        "            test_probs = train_model.predict(x=testX, batch_size=batch_size)\n",
        "            cmatrix = tf.math.confusion_matrix(labels=np.reshape(testY, (len(testY),)), predictions=np.reshape(np.argmax(test_probs, axis=-1), (len(test_probs),)), num_classes=None)\n",
        "            # conf_numpy = sess.run(cmatrix)\n",
        "            conf_df = pd.DataFrame(cmatrix, index=all_labels ,columns=all_labels)\n",
        "            conf_fig = sn.heatmap(conf_df, annot=True, fmt=\"d\", cmap=\"BuPu\")\n",
        "            plt.xlabel('Prediction', fontsize=16)\n",
        "            plt.ylabel('Ground Truth', fontsize=16)\n",
        "            cmatrix_fig = conf_fig.get_figure()\n",
        "            cmatrix_fig.savefig(os.path.join(result_dir, 'e'+str(epoch)+'_testacc_'+str(round(test_acc,3))+'_confusion_matrix.png'), dpi=400)\n",
        "            plt.close()\n",
        "            \n",
        "\n",
        "            prediction_probs = train_model.predict(x=predictX, batch_size=batch_size)\n",
        "            with open(os.path.join(result_dir, 'e'+str(epoch)+'_testacc_'+str(round(test_acc,3))+'_unassociate_prediction.log'), 'w') as fp:\n",
        "                fp.write('\\n\\n=========== prediction ===========\\n')\n",
        "                fp.write('index\\tsource_name\\tprediction\\tprobability\\n')\n",
        "                for i in range(len(prediction_probs)):\n",
        "                    fp.write(str(i) + '\\t' + predict_sourcename[i] + '\\t' + str(int(np.argmax(prediction_probs[i]))) + '\\t' + str(np.max(prediction_probs[i])) + '\\n')\n",
        "            \n",
        "\n",
        "    with open(os.path.join(result_dir, 'results.log'), 'w') as fp:\n",
        "        fp.write('epoch\\ttrain_loss\\tval_loss\\ttest_loss\\ttrain_acc\\tval_acc\\ttest_acc\\n')\n",
        "        for i in range(epochs):\n",
        "            fp.write(str(i+1)+'\\t'+str(round(train_loss_list[i],5))+'\\t'+str(round(val_loss_list[i],5))+'\\t'+str(round(test_loss_list[i],5))+'\\t'+str(round(train_acc_list[i],5))+'\\t'+str(round(val_acc_list[i],5))+'\\t'+str(round(test_acc_list[i],5))+'\\n')\n",
        "\n",
        "\n",
        "    epoch_list = [i+1 for i in range(epochs)]\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_list, train_loss_list, color='r', label='train')\n",
        "    plt.plot(epoch_list, val_loss_list, color='b', label='validation')\n",
        "    plt.plot(epoch_list, test_loss_list, color='g', label='test')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "    plt.savefig(os.path.join(result_dir, 'loss.png'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epoch_list, train_acc_list, color='r', label='train')\n",
        "    plt.plot(epoch_list, val_acc_list, color='b', label='validation')\n",
        "    plt.plot(epoch_list, test_acc_list, color='g', label='test')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "    plt.savefig(os.path.join(result_dir, 'accuracy.png'))\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_repeat = 10\n",
        "check_info = [ # [data_npy_dir, mission_str]\n",
        "    [r'datasets/NPY_DATA_A', 'Mission_A'],\n",
        "    [r'datasets/NPY_DATA_B', 'Mission_B'],\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_npy_dir, mission_str in check_info:\n",
        "\n",
        "    if mission_str == 'Mission_A':\n",
        "        important_attribute_index = myparams.important_attribute_index_missionA\n",
        "        core_attribute_index = myparams.core_attribute_index_missionA\n",
        "    else:\n",
        "        important_attribute_index = myparams.important_attribute_index_missionB\n",
        "        core_attribute_index = myparams.core_attribute_index_missionB\n",
        "\n",
        "    # feature importance\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'Feature_Importance_RF', 'TRAIN', 'RF')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "        \n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in important_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "            gridSearch_reduceAttributes_RF(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, len(reduce_index), result_dir, 'FeatureImportance', split_num)\n",
        "    \n",
        "\n",
        "\n",
        "    # PCA\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'PCA', 'TRAIN', 'RF')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        for important_component in myparams.important_component_num:\n",
        "            gridSearch_PCA_RF(trainX, trainY, validationX, validationY, testX, testY, test_sourcename, predict_data, predict_sourcename, important_component, result_dir, split_num)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # FDASE\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'FDASE', 'TRAIN', 'RF')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in core_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "\n",
        "            gridSearch_reduceAttributes_RF(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, len(reduce_index), result_dir, 'FDASE', split_num)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_npy_dir, mission_str in check_info:\n",
        "\n",
        "    if mission_str == 'Mission_A':\n",
        "        important_attribute_index = myparams.important_attribute_index_missionA\n",
        "        core_attribute_index = myparams.core_attribute_index_missionA\n",
        "    else:\n",
        "        important_attribute_index = myparams.important_attribute_index_missionB\n",
        "        core_attribute_index = myparams.core_attribute_index_missionB\n",
        "\n",
        "    # feature importance\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'Feature_Importance_RF', 'TRAIN', 'SVM')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "        \n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in important_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "            gridSearch_SVM(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, result_dir, 'FeatureImportance', len(reduce_index), split_num)\n",
        "    \n",
        "\n",
        "\n",
        "    # PCA\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'PCA', 'TRAIN', 'SVM')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        for important_component in myparams.important_component_num:\n",
        "            gridSearch_SVM(trainX, trainY, validationX, validationY, testX, testY, test_sourcename, predict_data, predict_sourcename, result_dir, 'PCA', important_component, split_num)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # FDASE\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'FDASE', 'TRAIN', 'SVM')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in core_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "\n",
        "            gridSearch_SVM(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, result_dir, 'FDASE', len(reduce_index), split_num)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_npy_dir, mission_str in check_info:\n",
        "\n",
        "    if mission_str == 'Mission_A':\n",
        "        important_attribute_index = myparams.important_attribute_index_missionA\n",
        "        core_attribute_index = myparams.core_attribute_index_missionA\n",
        "    else:\n",
        "        important_attribute_index = myparams.important_attribute_index_missionB\n",
        "        core_attribute_index = myparams.core_attribute_index_missionB\n",
        "\n",
        "    # feature importance\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'Feature_Importance_RF', 'TRAIN', 'AdaBoost')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "        \n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in important_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "            gridSearch_AdaBoost(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, result_dir, 'FeatureImportance', len(reduce_index), split_num)\n",
        "    \n",
        "\n",
        "\n",
        "    # PCA\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'PCA', 'TRAIN', 'AdaBoost')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        for important_component in myparams.important_component_num:\n",
        "            gridSearch_AdaBoost(trainX, trainY, validationX, validationY, testX, testY, test_sourcename, predict_data, predict_sourcename, result_dir, 'PCA', important_component, split_num)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # FDASE\n",
        "    result_dir = os.path.join('RESULTS', mission_str, 'FDASE', 'TRAIN', 'AdaBoost')\n",
        "    if os.path.exists(result_dir):\n",
        "        shutil.rmtree(result_dir)\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predict_data, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        for important_attribute in core_attribute_index:\n",
        "            reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "            reduced_trainX = np.delete(trainX, reduce_index, axis=1)\n",
        "            reduced_validationX = np.delete(validationX, reduce_index, axis=1)\n",
        "            reduced_testX = np.delete(testX, reduce_index, axis=1)\n",
        "            reduced_predictX = np.delete(predict_data, reduce_index, axis=1)\n",
        "\n",
        "            gridSearch_AdaBoost(reduced_trainX, trainY, reduced_validationX, validationY, reduced_testX, testY, test_sourcename, reduced_predictX, predict_sourcename, result_dir, 'FDASE', len(reduce_index), split_num)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_output_classes = 2\n",
        "model_hidden_units = [32,32,64,32,32]\n",
        "model_dropout_list = [0.5,0.5,0.5,0.5,0.5]\n",
        "model_act_fn = 'leaky_relu'\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 500\n",
        "# epochs = 5\n",
        "learning_rate = 0.0005\n",
        "\n",
        "preprocessing_methods = ['Feature_Importance_RF', 'PCA', 'FDASE']\n",
        "classifier_str = 'MLP'\n",
        "\n",
        "\n",
        "\n",
        "for data_npy_dir, mission_str in check_info:\n",
        "\n",
        "    if mission_str == 'Mission_A':\n",
        "        important_attribute_index = myparams.important_attribute_index_missionA\n",
        "        core_attribute_index = myparams.core_attribute_index_missionA\n",
        "    else:\n",
        "        important_attribute_index = myparams.important_attribute_index_missionB\n",
        "        core_attribute_index = myparams.core_attribute_index_missionB\n",
        "\n",
        "\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predictX, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "        all_attribute_index = [i for i in range(len(header_name))]\n",
        "        trainX_scaled = scale(trainX, axis=0)\n",
        "        validationX_scaled = scale(validationX, axis=0)\n",
        "        testX_scaled = scale(testX, axis=0)\n",
        "        predictX_scaled = scale(predictX, axis=0)\n",
        "\n",
        "\n",
        "        for i in range(len(preprocessing_methods)):\n",
        "            prepro_str = preprocessing_methods[i]\n",
        "\n",
        "            if prepro_str == 'PCA':\n",
        "                for important_component in myparams.important_component_num:\n",
        "                    result_dir = os.path.join('RESULTS', mission_str, prepro_str, 'TRAIN', classifier_str, 'split_'+str(split_num)+'_component_'+str(important_component))\n",
        "                    if os.path.exists(result_dir):\n",
        "                        shutil.rmtree(result_dir)\n",
        "                    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "                    pca = PCA(n_components=important_component)\n",
        "                    trainX = pca.fit_transform(trainX_scaled)\n",
        "                    validationX = pca.transform(validationX_scaled)\n",
        "                    testX = pca.transform(testX_scaled)\n",
        "                    predictX = pca.transform(predictX_scaled)\n",
        "\n",
        "                    MLP_train(model_output_classes, model_hidden_units, model_dropout_list, model_act_fn,\n",
        "                        trainX, validationX, testX, trainY, validationY, testY, predictX, predict_sourcename,\n",
        "                        result_dir, batch_size, epochs, learning_rate)\n",
        "\n",
        "            else:\n",
        "                if prepro_str == 'Feature_Importance_RF':\n",
        "                    retain_attribute_index = important_attribute_index\n",
        "                elif prepro_str == 'FDASE':\n",
        "                    retain_attribute_index = core_attribute_index\n",
        "\n",
        "                for important_attribute in retain_attribute_index:\n",
        "                    reduce_index = list(set(all_attribute_index) - set(important_attribute))\n",
        "                    result_dir = os.path.join('RESULTS', mission_str, prepro_str, 'TRAIN', classifier_str, 'split_'+str(split_num)+'_reduce_'+str(len(reduce_index)))\n",
        "                    if os.path.exists(result_dir):\n",
        "                        shutil.rmtree(result_dir)\n",
        "                    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "                    trainX = np.delete(trainX_scaled, reduce_index, axis=1)\n",
        "                    validationX = np.delete(validationX_scaled, reduce_index, axis=1)\n",
        "                    testX = np.delete(testX_scaled, reduce_index, axis=1)\n",
        "                    predictX = np.delete(predictX_scaled, reduce_index, axis=1)\n",
        "\n",
        "                    MLP_train(model_output_classes, model_hidden_units, model_dropout_list, model_act_fn,\n",
        "                        trainX, validationX, testX, trainY, validationY, testY, predictX, predict_sourcename,\n",
        "                        result_dir, batch_size, epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Proposed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prepro_str = 'FDIDWT'\n",
        "classifier_str = 'CONV1D'\n",
        "batch_size = 64\n",
        "epochs = 500\n",
        "learning_rate = 0.0005\n",
        "debug_str = 'proposed_demo'\n",
        "\n",
        "\n",
        "for data_npy_dir, mission_str in check_info:\n",
        "    for split_num in range(1, split_repeat+1):\n",
        "        trainX, validationX, testX, \\\n",
        "        trainY, validationY, testY, \\\n",
        "        train_sourcename, validation_sourcename, test_sourcename, \\\n",
        "        predictX, predict_sourcename, header_name = utils.load_npy_data(data_npy_dir, split_num, delete_attris_list=['Unc_Flux1000', 'Unc_PL_Index', 'Unc_Frac_Variability'])\n",
        "\n",
        "\n",
        "\n",
        "        level_data_dir = os.path.join('RESULTS', mission_str, 'FDIDWT', 'step2_4_2_iwt_outputs', 'split_'+str(split_num))\n",
        "        file_path_list = utils.return_FDIDWT_files(level_data_dir)\n",
        "        result_base_dir = os.path.join('RESULTS', mission_str, 'Proposed', debug_str, 'split_'+str(split_num))\n",
        "        os.makedirs(result_base_dir, exist_ok=True)\n",
        "\n",
        "        for_train_data_dict = {}\n",
        "        for file in file_path_list:\n",
        "            keyword = os.path.basename(os.path.dirname(file)) + '_' + '_'.join(os.path.basename(file).split('.txt')[0].split('_')[:-1])\n",
        "            if keyword not in for_train_data_dict:\n",
        "                for_train_data_dict[keyword] = [file]\n",
        "            else:\n",
        "                for_train_data_dict[keyword].append(file)\n",
        "\n",
        "\n",
        "        for kw, filelist in for_train_data_dict.items():\n",
        "            for file in filelist:\n",
        "                basename = os.path.basename(file)\n",
        "                n_reduced = np.shape(trainX)[-1] - int(basename.split('_')[0].split('outputDim')[-1])\n",
        "\n",
        "                if 'train' in basename:\n",
        "                    FDIDWT_trainX = utils.load_FDIDWT_data(file)\n",
        "                elif 'validation' in basename:\n",
        "                    FDIDWT_validationX = utils.load_FDIDWT_data(file)\n",
        "                elif 'test' in basename:\n",
        "                    FDIDWT_testX = utils.load_FDIDWT_data(file)\n",
        "                elif 'un' in basename:\n",
        "                    FDIDWT_predictX = utils.load_FDIDWT_data(file)\n",
        "                else:\n",
        "                    print('error file:', file)\n",
        "                    exit()\n",
        "\n",
        "\n",
        "            result_dir = os.path.join(result_base_dir, kw)\n",
        "            if not os.path.exists(result_dir):\n",
        "                os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "                proposed_train(FDIDWT_trainX, FDIDWT_validationX, FDIDWT_testX, trainY, validationY, testY, FDIDWT_predictX, predict_sourcename,\n",
        "                    result_dir, batch_size, epochs, learning_rate)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "01_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.16 ('tf29')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "00f10844da1a03447938456ee73c08f72d39e9b8baab80c01d0948b98bbe2238"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
