{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fathHzuEgx8_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_nan(nan):\n",
        "    return nan != nan\n",
        "\n",
        "\n",
        "def read_excel_data(excel_path,\n",
        "                    delete_cols=[],\n",
        "                    delete_sourcename=[]):\n",
        "    df = pd.read_excel(excel_path)\n",
        "    header_name_list = list(df.head())\n",
        "    all_data = np.array(df)\n",
        "    all_data = np.concatenate([np.reshape(header_name_list, (1, -1)), all_data], axis=0)\n",
        "    print('all_data shape: {}'.format(np.shape(all_data)))\n",
        "\n",
        "    row, col = np.shape(all_data)\n",
        "    source_name_list, header_name_list, label_list, data = [], [], [], [] # np.zeros((row, col-2))\n",
        "\n",
        "    for i in range(row):\n",
        "        row_data = []\n",
        "        for j in range(col):\n",
        "            if i == 0:\n",
        "                if 'Source_Name' == all_data[i, j]:\n",
        "                    source_name_index = j\n",
        "                    print('source_name_index: {}'.format(source_name_index))\n",
        "                    continue\n",
        "                elif 'Class_Xiao' == all_data[i, j]:\n",
        "                    label_name_index = j\n",
        "                    print('label_name_index: {}'.format(label_name_index))\n",
        "                    continue\n",
        "                header_name_list.append(all_data[i, j])\n",
        "            else:\n",
        "                if source_name_index == j:\n",
        "                    source_name = all_data[i, j]\n",
        "                    if source_name in delete_sourcename:\n",
        "                        break\n",
        "                    else:\n",
        "                        source_name_list.append(source_name)\n",
        "                elif label_name_index == j:\n",
        "                    label_list.append(all_data[i, j])\n",
        "                else:\n",
        "                    try:\n",
        "                        row_data.append(float(all_data[i, j]))\n",
        "                    except:\n",
        "                        print('error in ({}, {}) -> {}'.format(i, j, all_data[i, j]))\n",
        "        if len(row_data) > 0:\n",
        "            data.append(row_data)\n",
        "\n",
        "    return source_name_list, header_name_list, label_list, np.array(data)\n",
        "\n",
        "\n",
        "\n",
        "def pick_wanted_samples(source_name_list, label_list, data, wanted_labels):\n",
        "    wanted_data_dict = {}\n",
        "    wanted_sourcename_dict = {}\n",
        "    for i in range(len(label_list)):\n",
        "        if not is_nan(label_list[i]):\n",
        "            label = label_list[i].lower()\n",
        "            if label in wanted_labels:\n",
        "                if label not in wanted_data_dict.keys():\n",
        "                    wanted_data_dict[label] = [data[i]]\n",
        "                    wanted_sourcename_dict[label] = [source_name_list[i]]\n",
        "                else:\n",
        "                    wanted_data_dict[label].append(data[i])\n",
        "                    wanted_sourcename_dict[label].append(source_name_list[i])\n",
        "    return wanted_sourcename_dict, wanted_data_dict\n",
        "\n",
        "\n",
        "\n",
        "def process_nan_values(input_data):\n",
        "    output_data = np.copy(input_data)\n",
        "    row, col = np.shape(input_data)\n",
        "    for j in range(col):\n",
        "        col_data = input_data[:, j]\n",
        "        col_data_ = []\n",
        "        for i in range(row):\n",
        "            d = input_data[i, j]\n",
        "            if not is_nan(d):\n",
        "                col_data_.append(d)\n",
        "        mean_value = np.mean(col_data_)\n",
        "        for i in range(row):\n",
        "            d = output_data[i, j]\n",
        "            if is_nan(d):\n",
        "                output_data[i, j] = mean_value\n",
        "        if len(col_data_) != row:\n",
        "            print('col: {}, mean: {}, has NaN {}'.format(j, mean_value, row-len(col_data_)))\n",
        "    \n",
        "    checked = True\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            if is_nan(output_data[i, j]):\n",
        "                checked = False\n",
        "    \n",
        "    if checked:\n",
        "        return output_data\n",
        "    else:\n",
        "        print('still has NaN values')\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_original_file(src_file, target_file, wanted_labels_list):\n",
        "    save_data_dict = {} # the data to be saved in target_file\n",
        "\n",
        "    # read the src_file, remove some cols and rows\n",
        "    source_name_list, header_name_list, label_list, data = read_excel_data(src_file)\n",
        "    wanted_sourcename_dict, wanted_data_dict_ = pick_wanted_samples(source_name_list, label_list, data, wanted_labels=wanted_labels_list)\n",
        "    \n",
        "    # build the headers\n",
        "    save_data_dict['source_name'] = []\n",
        "    save_data_dict['label'] = []\n",
        "    for header_name in header_name_list:\n",
        "        save_data_dict[header_name] = []\n",
        "\n",
        "    \n",
        "    wanted_data_dict = {}\n",
        "    for k, v in wanted_data_dict_.items():\n",
        "        wanted_data_dict[k] = process_nan_values(np.array(v))\n",
        "        print(k, np.shape(wanted_data_dict[k]))\n",
        "    \n",
        "    \n",
        "    for label_name, source_data in wanted_data_dict.items():\n",
        "        row, col = np.shape(source_data)\n",
        "        assert col == len(header_name_list)\n",
        "        assert row == len(wanted_sourcename_dict[label_name])\n",
        "        for i in range(row):\n",
        "            save_data_dict['source_name'].append(wanted_sourcename_dict[label_name][i])\n",
        "            save_data_dict['label'].append(label_name)\n",
        "            for j in range(col):\n",
        "                header_name = header_name_list[j]\n",
        "                d = source_data[i, j]\n",
        "                save_data_dict[header_name].append(d)\n",
        "    \n",
        "    save_data_dict = pd.DataFrame(save_data_dict)\n",
        "    save_data_dict.to_excel(target_file)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_data shape: (6660, 18)\n",
            "source_name_index: 0\n",
            "label_name_index: 9\n",
            "un (2291, 16)\n",
            "agn (3809, 16)\n",
            "col: 2, mean: 2.2397136912783155e-10, has NaN 1\n",
            "col: 3, mean: 2.344321295519713, has NaN 1\n",
            "col: 4, mean: 0.06511966051225807, has NaN 1\n",
            "col: 5, mean: 18.91627668297491, has NaN 1\n",
            "col: 6, mean: 0.07948483414293907, has NaN 1\n",
            "col: 7, mean: 6.081420805236918, has NaN 1\n",
            "non-agn (559, 16)\n"
          ]
        }
      ],
      "source": [
        "src_file = r'datasets\\4FGL_DR3_Data_A.xlsx'\n",
        "target_file = r'datasets\\Dataset_A.xlsx'\n",
        "wanted_labels_list = ['agn', 'non-agn', 'un']\n",
        "process_original_file(src_file, target_file, wanted_labels_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_data shape: (3744, 18)\n",
            "source_name_index: 0\n",
            "label_name_index: 9\n",
            "bcu (1493, 16)\n",
            "bll (1456, 16)\n",
            "fsrq (794, 16)\n"
          ]
        }
      ],
      "source": [
        "src_file = r'datasets\\4FGL_DR3_Data_B.xlsx'\n",
        "target_file = r'datasets\\Dataset_B.xlsx'\n",
        "wanted_labels_list = ['bcu', 'bll', 'fsrq']\n",
        "process_original_file(src_file, target_file, wanted_labels_list)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "01_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.16 ('tf29')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "00f10844da1a03447938456ee73c08f72d39e9b8baab80c01d0948b98bbe2238"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
